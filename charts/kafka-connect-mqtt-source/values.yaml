# Basic info
replicaCount: "__REQUIRED__"
secretsRef: "__REQUIRED__"
image:
  repository: registry.hub.docker.com/datamountaineer/kafka-connect-mqtt-source
  tag: 0.3.0
  pullPolicy: IfNotPresent

# Resource management
resources:
  limits:
    memory: 512Mi
  requests:
    memory: 256Mi
javaHeap: 256M

# Monitoring
monitoring:
  pipeline: "__REQUIRED__"
  enabled: true
  port: 9102
  path: "/metrics"

# SSL/TLS options can be enabled, some connectors provide SSL support, others the newer TLS
# Set the corresponding value type to true. For SSL persistent volumes or hostPaths will be
# mounted under /connector-extra-config. Set the connectors ssl/tls option paths to be use this
# TLS is done via Secrets, create a secret for containing the certificates (base64 encoded) and
# create a secret for them, adding the name of the secret to the `secretsRef` other wise if using
# Eneco's Landscaper it will do this for you.

# SSL mount path on hosts, should be the base path of any ssl keystore/truststore paths
ssl:
  enabled: false
  # Path to the directory on the hosts
  path: /ssl

  # If persistent volumes should be used for ssl keystore/truststore paths
  persistentVolumes:
    enable: false
    existingClaim:

# TLS, for those connectors supporting TLS certificates rather than ssl key/truststores
# contents for mount take from config map
tls:
  enabled: false

## Avro schemas, for those connectors, MQTT and JMS source that support Avro converters we
## need the schemas, so we'll mount as a ConfigMap. Set the key value pairs, filename and data
## matching the value option avroSchema. Key is the file name, value is the avro schema contents
#avroSchemaFiles:
#  schema_file_name:  ""






# username Contains the Mqtt connection user name type: STRING importance: HIGH
username: 

# clean connect.mqtt.clean type: BOOLEAN importance: LOW
clean: true

# sslKey Certificate private [config] key file path. type: STRING importance: MEDIUM
sslKey: 

# timeout Provides the time interval to establish the mqtt connection type: INT importance: LOW
timeout: 3000

# converterThrowOnError 
#  If set to false the conversion exception will be swallowed and everything carries on BUT the message is lost!!;
#  true will throw the exception.Default is false.
#      type: BOOLEAN importance: HIGH
converterThrowOnError: false

# sslCaCert Provides the path to the CA certificate file to use with the Mqtt connection type: STRING importance: MEDIUM
sslCaCert: 

# enabled Enables the output for how many records have been processed type: BOOLEAN importance: MEDIUM
enabled: false

# hosts Contains the MQTT connection end points. type: STRING importance: HIGH
hosts: "__REQUIRED__"

# clientId Contains the Mqtt session client id type: STRING importance: LOW
clientId: 

# sslCert Provides the path to the certificate file to use with the Mqtt connection type: STRING importance: MEDIUM
sslCert: 

# serviceQuality Specifies the Mqtt quality of service type: INT importance: MEDIUM
serviceQuality: "__REQUIRED__"

# kcql Contains the Kafka Connect Query Language describing the sourced MQTT source and the target Kafka topics type: STRING importance: HIGH
kcql: "__REQUIRED__"

# keepAlive 
#  The keep alive functionality assures that the connection is still open and both broker and client are connected to
#  the broker during the establishment of the connection. The interval is the longest possible period of time,
#  which broker and client can endure without sending a message.
#      type: INT importance: LOW
keepAlive: 5000

# password Contains the Mqtt connection password type: PASSWORD importance: HIGH
password: "__REQUIRED__"

# avroSchemas If the AvroConverter is used you need to provide an avro Schema to be able to read and translate the raw bytes to an avro record. The format is $MQTT_TOPIC=$PATH_TO_AVRO_SCHEMA_FILE type: STRING importance: HIGH
avroSchemas: 

